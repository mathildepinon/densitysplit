{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce39e971-c1a3-4659-9944-d1c65141de34",
   "metadata": {},
   "source": [
    "# Compute correlation function with error bars using log-normal mocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d0828b-b7b6-4536-bc95-3e2c507f9778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from scipy import optimize as opt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "from pycorr import TwoPointCorrelationFunction\n",
    "\n",
    "from densitysplit import catalog_data, density_split\n",
    "from bin.density_split_mocks_functions import split_density, compute_densitySplit_CCF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d92a85f-b500-43ab-8097-299f2d97611b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data and output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c040497-6f71-42de-9142-b88c6e672c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/feynman/work/dphp/mp270220/data/'\n",
    "output_dir = '/feynman/work/dphp/mp270220/outputs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e1d5f-7796-49a9-9891-1802a5ed8896",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "743e720f-1851-4b56-8953-edf0a9ffe1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_name = 'AbacusSummit_1Gpc_z1.175'\n",
    "bias = 1.8\n",
    "\n",
    "#catalog_name = 'AbacusSummit_2Gpc_z1.175'\n",
    "#bias = 3.\n",
    "\n",
    "#catalog_name = 'AbacusSummit_2Gpc_z0.800'\n",
    "#catalog_name = 'mock'\n",
    "\n",
    "catalog = catalog_data.Data.load(data_dir+catalog_name+'.npy')\n",
    "catalog.shift_boxcenter(-catalog.offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2168ea6-eae9-4cc5-99d7-012e64d137ca",
   "metadata": {},
   "source": [
    "## Split density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3979c51-5e6d-4c74-a642-8f549af1414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000000.08] [0/1] 05-17 15:21  CatalogMesh               INFO     Slab 0 ~ 4194304 / 2934922.\n",
      "[000000.79] [0/1] 05-17 15:21  CatalogMesh               INFO     Painted 2934922 out of 2934922 objects to mesh.\n",
      "[000001.56] [0/1] 05-17 15:21  TwoPointCorrelationFunction INFO     Using estimator <class 'pycorr.twopoint_estimator.NaturalTwoPointEstimator'>.\n",
      "[000001.56] [0/1] 05-17 15:21  TwoPointCorrelationFunction INFO     Computing two-point counts D1D2.\n",
      "[000010.49] [0/1] 05-17 15:21  TwoPointCorrelationFunction INFO     Analytically computing two-point counts R1R2.\n",
      "[000010.49] [0/1] 05-17 15:21  TwoPointCorrelationFunction INFO     Using estimator <class 'pycorr.twopoint_estimator.NaturalTwoPointEstimator'>.\n",
      "[000010.49] [0/1] 05-17 15:21  TwoPointCorrelationFunction INFO     Computing two-point counts D1D2.\n",
      "[000022.40] [0/1] 05-17 15:22  TwoPointCorrelationFunction INFO     Analytically computing two-point counts R1R2.\n",
      "[000022.40] [0/1] 05-17 15:22  TwoPointCorrelationFunction INFO     Using estimator <class 'pycorr.twopoint_estimator.NaturalTwoPointEstimator'>.\n",
      "[000022.40] [0/1] 05-17 15:22  TwoPointCorrelationFunction INFO     Computing two-point counts D1D2.\n",
      "[000063.00] [0/1] 05-17 15:22  TwoPointCorrelationFunction INFO     Analytically computing two-point counts R1R2.\n",
      "[000063.01] [0/1] 05-17 15:22  TwoPointCorrelationFunction INFO     Using estimator <class 'pycorr.twopoint_estimator.NaturalTwoPointEstimator'>.\n",
      "[000063.01] [0/1] 05-17 15:22  TwoPointCorrelationFunction INFO     Computing two-point counts D1D2.\n",
      "[000071.43] [0/1] 05-17 15:23  TwoPointCorrelationFunction INFO     Analytically computing two-point counts R1R2.\n",
      "[000071.44] [0/1] 05-17 15:23  TwoPointCorrelationFunction INFO     Using estimator <class 'pycorr.twopoint_estimator.NaturalTwoPointEstimator'>.\n",
      "[000071.44] [0/1] 05-17 15:23  TwoPointCorrelationFunction INFO     Computing two-point counts D1D2.\n",
      "[000083.92] [0/1] 05-17 15:23  TwoPointCorrelationFunction INFO     Analytically computing two-point counts R1R2.\n",
      "[000083.93] [0/1] 05-17 15:23  TwoPointCorrelationFunction INFO     Using estimator <class 'pycorr.twopoint_estimator.NaturalTwoPointEstimator'>.\n",
      "[000083.93] [0/1] 05-17 15:23  TwoPointCorrelationFunction INFO     Computing two-point counts D1D2.\n",
      "[000093.03] [0/1] 05-17 15:23  TwoPointCorrelationFunction INFO     Analytically computing two-point counts R1R2.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'gg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m ells \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     10\u001b[0m nells \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ells)\n\u001b[0;32m---> 11\u001b[0m catalog_split_xiell_gg \u001b[38;5;241m=\u001b[39m [result\u001b[38;5;241m.\u001b[39mget_corr(ells\u001b[38;5;241m=\u001b[39mells, return_sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcatalog_CCFs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     12\u001b[0m catalog_split_xiell_dg \u001b[38;5;241m=\u001b[39m [result\u001b[38;5;241m.\u001b[39mget_corr(ells\u001b[38;5;241m=\u001b[39mells, return_sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m catalog_CCFs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdg\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gg'"
     ]
    }
   ],
   "source": [
    "cellsize = 10\n",
    "resampler = 'tsc'\n",
    "\n",
    "catalog_density = split_density(catalog, cellsize, resampler, nsplits=2, save=False, output_dir=output_dir)\n",
    "\n",
    "edges = (np.linspace(0., 150., 51), np.linspace(-1, 1, 201))\n",
    "catalog_CCFs = compute_densitySplit_CCF(catalog_density, edges, los='x')\n",
    "\n",
    "ells = (0, 2)\n",
    "nells = len(ells)\n",
    "catalog_split_xiell_gg = [result.get_corr(ells=ells, return_sep=False) for result in catalog_CCFs['gg']]\n",
    "catalog_split_xiell_dg = [result.get_corr(ells=ells, return_sep=False) for result in catalog_CCFs['dg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3165a80e-f879-4358-9811-765a21940d9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mcatalog_CCFs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mseps[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gg'"
     ]
    }
   ],
   "source": [
    "s = catalog_CCFs['gg'][0].seps[0][:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1f677f-8fab-4333-a4cd-97bb912f749c",
   "metadata": {},
   "source": [
    "## Generate log-normal mocks and compute cross-correlation function on density splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a33d562-2dc2-4609-8f85-3ed4ba22dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmocks = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d613cd73-25ef-4638-8017-7f8f93b04dbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/feynman/work/dphp/mp270220/outputs/AbacusSummit_1Gpc_z1.175_1000_mocks_densitySplit_hh_CCF_cellsize10.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_gg \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mcatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_1000_mocks_densitySplit_hh_CCF_cellsize10.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m results_dg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(output_dir\u001b[38;5;241m+\u001b[39mcatalog\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_1000_mocks_densitySplit_hh_CCF_cellsize10.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/feynman/work/dphp/adematti/cosmodesiconda/20220419-1.0.0/conda/lib/python3.9/site-packages/numpy/lib/npyio.py:417\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 417\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    418\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/feynman/work/dphp/mp270220/outputs/AbacusSummit_1Gpc_z1.175_1000_mocks_densitySplit_hh_CCF_cellsize10.npy'"
     ]
    }
   ],
   "source": [
    "results_gg = np.load(output_dir+catalog.name+'_1000_mocks_densitySplit_hh_CCF_cellsize10.npy', allow_pickle=True)\n",
    "results_dg = np.load(output_dir+catalog.name+'_1000_mocks_densitySplit_hh_CCF_cellsize10.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a29dc1-75d9-468d-9398-671e72f8f7ec",
   "metadata": {},
   "source": [
    "## Compute covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c7d608-d084-4215-afb1-60c17b97ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poles(results, ells):\n",
    "    nells = len(ells)\n",
    "    n = len(results)\n",
    "    nsplits = len(results[0])\n",
    "    \n",
    "    xiell = list()\n",
    "    cov = list()\n",
    "    \n",
    "    for i in range(nsplits):\n",
    "        results_poles = [np.ravel(res[i].get_corr(ells=ells, return_sep=False)) for res in results]\n",
    "        poles = np.mean(results_poles, axis=0)\n",
    "        xiell.append(poles.reshape((nells, len(poles)//nells)))\n",
    "    \n",
    "    cov = np.cov([np.ravel([res[i].get_corr(ells=ells, return_sep=False) for i in range(nsplits)]) for res in results], rowvar=False)\n",
    "\n",
    "    return xiell, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dcda87-fea9-4348-8c5c-1de4cc07feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ells = [0]\n",
    "nells = len(ells)\n",
    "\n",
    "xiell_gg, cov_gg = get_poles(results_gg, ells)\n",
    "xiell_dg, cov_dg = get_poles(results_dg, ells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03aacab-f573-4c28-95bd-b34bd3208eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(output_dir+catalog.name+'_1000_mocks_densitySplit_gg_CCF_monopole_cov', (s, xiell_gg, cov_gg))\n",
    "#np.save(output_dir+catalog.name+'_1000_mocks_densitySplit_dg_CCF_monopole_cov', (s, xiell_dg, cov_dg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0309b9ac-6bc3-44fc-815a-599ee2c3ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsplits = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6aa03c-8333-4799-aa36-d635bc756d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_gg = np.array_split(np.array(np.array_split(np.diag(cov_gg)**0.5, nells)), nsplits, axis=1)\n",
    "std_dg = np.array_split(np.array(np.array_split(np.diag(cov_dg)**0.5, nells)), nsplits, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a29521-cb6f-460b-af36-8e1a0da64f88",
   "metadata": {},
   "source": [
    "## Covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630513d8-1cb8-4d2b-a8b5-284553c1a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stddev_gg = np.sqrt(np.diag(cov_gg).real)\n",
    "corrcoef_gg = cov_gg / stddev_gg[:, None] / stddev_gg[None, :]\n",
    "stddev_dg = np.sqrt(np.diag(cov_dg).real)\n",
    "corrcoef_dg = cov_dg / stddev_dg[:, None] / stddev_dg[None, :]\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def plot_corrcoef(corrcoef, ells, s):\n",
    "    ns = len(s)\n",
    "    nells = len(ells)\n",
    "    \n",
    "    fig, lax = plt.subplots(nrows=nells*nsplits, ncols=nells*nsplits, sharex=False, sharey=False, figsize=(10, 8), squeeze=False)\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "\n",
    "    norm = Normalize(vmin=corrcoef.min(), vmax=corrcoef.max())\n",
    "    for i in range(nells*nsplits):\n",
    "        for j in range(nells*nsplits):\n",
    "            ax = lax[nells*nsplits-1-i][j]\n",
    "            mesh = ax.pcolor(s, s, corrcoef[i*ns:(i+1)*ns,j*ns:(j+1)*ns].T, norm=norm, cmap=plt.get_cmap('coolwarm'))\n",
    "            if i>0: ax.xaxis.set_visible(False)\n",
    "            else: ax.set_xlabel(r'$s$  [Mpc/h]'\n",
    "                                #+'\\n'+r'$\\ell={}$'.format(ells[j//nsplits])\n",
    "                                +'\\n''DS{}'.format(j//nells +1))\n",
    "            if j>0: ax.yaxis.set_visible(False)\n",
    "            else: ax.set_ylabel('DS{}'.format(i//nells +1)\n",
    "                                #+'\\n'+r'$\\ell={}$'.format(ells[i//nsplits])\n",
    "                                +'\\n'+r'$s$  [Mpc/h]')\n",
    "    fig.colorbar(mesh, ax=lax, label=r'$r$')\n",
    "    plt.show()\n",
    "    \n",
    "plot_corrcoef(corrcoef_gg, ells, s)\n",
    "plot_corrcoef(corrcoef_dg, ells, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797be48a-abbb-4722-8ebf-c24e432a6659",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot correlation function with error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ca8b9-5615-4c10-b60e-d361a867296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=False)\n",
    "\n",
    "for i in range(catalog_density.nsplits):\n",
    "    \n",
    "    axes[0][i].plot(s, s**2 * catalog_split_xiell_gg[i][0], label='Abacus catalog')\n",
    "    axes[0][i].errorbar(s, s**2 * xiell_gg[i][0], s**2 * std_gg[i][0], fmt='-', label='{} mocks'.format(nmocks))\n",
    "    axes[0][i].grid(True)\n",
    "\n",
    "    axes[1][i].plot(s, s**2 * catalog_split_xiell_dg[i][0], label='Abacus catalog')\n",
    "    axes[1][i].errorbar(s, s**2 * xiell_dg[i][0], s**2 * std_dg[i][0], fmt='-', label='{} mocks'.format(nmocks))\n",
    "    axes[1][i].grid(True)\n",
    "\n",
    "    axes[0][i].set_title('DS{}'.format(i+1))    \n",
    "    axes[1][i].set_xlabel(r'$s$ [$\\mathrm{Mpc}/h$]')\n",
    "\n",
    "axes[0][0].set_ylabel('Halos in density split vs. halos' + '\\n'\n",
    "                      + r'$s^2 \\xi_0(s)$ [$(\\mathrm{Mpc}/h)^{2}$]')\n",
    "axes[0][1].set_ylabel(r'$s^2 \\xi_0(s)$ [$(\\mathrm{Mpc}/h)^{2}$]')\n",
    "axes[1][0].set_ylabel('Random points in density split vs. halos' + '\\n'\n",
    "                      + r'$s^2 \\xi_0(s)$ [$(\\mathrm{Mpc}/h)^{2}$]')\n",
    "axes[1][1].set_ylabel(r'$s^2 \\xi_0(s)$ [$(\\mathrm{Mpc}/h)^{2}$]')\n",
    "\n",
    "plt.suptitle('Catalog: box size = {:.0f} Mpc/$h$, $z$ = {:.3f}, real space'.format(catalog.boxsize, catalog.redshift),\n",
    "             ha='left', x=0.1, y=0)\n",
    "\n",
    "axes[0][1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22d558-31a4-4f70-abc6-8cc76be40433",
   "metadata": {},
   "source": [
    "## Add 2 Gpc catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fe6783-edd0-4e25-9deb-282f76adf53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog2 = catalog_data.Data.load(data_dir+'AbacusSummit_2Gpc_z1.175.npy')\n",
    "catalog2.shift_boxcenter(-catalog2.offset)\n",
    "catalog2_density = split_density(catalog2, cellsize, resampler, nsplits=2, save=False, output_dir=output_dir)\n",
    "catalog2_CCFs = compute_densitySplit_CCF(catalog2_density, edges, los='x')\n",
    "catalog2_split_xiell_gg = [result.get_corr(ells=ells, return_sep=False) for result in catalog2_CCFs['gg']]\n",
    "catalog2_split_xiell_dg = [result.get_corr(ells=ells, return_sep=False) for result in catalog2_CCFs['dg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940733d6-2d3d-412c-92c7-1ad3b7ad7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=False)\n",
    "\n",
    "for i in range(catalog_density.nsplits):\n",
    "    \n",
    "    axes[0][i].plot(s, s**2 * catalog_split_xiell_gg[i][0], label='Abacus catalog (1 Gpc/h)', color='C0')\n",
    "    axes[0][i].plot(s, s**2 * catalog2_split_xiell_gg[i][0], label='Abacus catalog (2 Gpc/h)', color='C2')\n",
    "    axes[0][i].errorbar(s, s**2 * xiell_gg[i][0], s**2 * std_gg[i][0], fmt='-', label='{} mocks'.format(nmocks), color='C1')\n",
    "    axes[0][i].grid(True)\n",
    "\n",
    "    axes[1][i].plot(s, s**2 * catalog_split_xiell_dg[i][0], label='Abacus catalog (1 Gpc/h)', color='C0')\n",
    "    axes[1][i].plot(s, s**2 * catalog2_split_xiell_dg[i][0], label='Abacus catalog (2 Gpc/h)', color='C2')\n",
    "    axes[1][i].errorbar(s, s**2 * xiell_dg[i][0], s**2 * std_dg[i][0], fmt='-', label='{} mocks'.format(nmocks), color='C1')\n",
    "    axes[1][i].grid(True)\n",
    "\n",
    "    axes[0][i].set_title('DS{}'.format(i+1))    \n",
    "    axes[1][i].set_xlabel(r'$s$ [$\\mathrm{Mpc}/h$]')\n",
    "\n",
    "axes[0][0].set_ylabel('Halos in density split vs. halos' + '\\n'\n",
    "                      + r'$s^2 \\xi_0(s)$ [$(\\mathrm{Mpc}/h)^{2}$]')\n",
    "axes[0][1].set_ylabel(r'$s^2 \\xi_0(s)$ [$(\\mathrm{Mpc}/h)^{2}$]')\n",
    "axes[1][0].set_ylabel('Random points in density split vs. halos' + '\\n'\n",
    "                      + r'$s^2 \\xi_0(s)$ [$(\\mathrm{Mpc}/h)^{2}$]')\n",
    "axes[1][1].set_ylabel(r'$s^2 \\xi_0(s)$ [$(\\mathrm{Mpc}/h)^{2}$]')\n",
    "\n",
    "plt.suptitle('Catalog: box size = {:.0f} Mpc/$h$, $z$ = {:.3f}, real space'.format(catalog.boxsize, catalog.redshift),\n",
    "             ha='left', x=0.1, y=0)\n",
    "\n",
    "axes[0][1].legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmodesi-1.0.0",
   "language": "python",
   "name": "cosmodesi-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
